{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iqra9999/Question-Answer-Generation-Pipeline-with-LLM/blob/main/QA_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNLIikXBcPSm",
        "outputId": "af5e925b-7fa7-4a71-d286-25e565160d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#First of all, mounting google drive to access input files and save output files in google drive\n",
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaeaDvMrfua9"
      },
      "source": [
        "# Preprocessing of news articles file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzO5eRzjcVrR",
        "outputId": "de7e9736-7cd1-480d-c7d3-478dd2811d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessed data saved to: /content/drive/My Drive/clean_news_data.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import re\n",
        "\n",
        "#The file contained various special characters in different formats, so everything is removed except the alphabets, integers and important characters.\n",
        "def clean_text(text):\n",
        "    #Removing words with extra spaces around\n",
        "    text = re.sub(r'\\s{2,}', ' ', text)\n",
        "\n",
        "    #Regular expression for characters that are allowed\n",
        "    pattern = r'[^a-zA-Z0-9,\\$\\(\\):\\;\\. ]'\n",
        "\n",
        "    #Replace the special characters with empty string\n",
        "    cleaned_text = re.sub(pattern, '', text)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "#Path of input file\n",
        "input_csv_file = '/content/drive/My Drive/news_dataset.csv'\n",
        "\n",
        "#Reading the csv file in a df\n",
        "df = pd.read_csv(input_csv_file)\n",
        "\n",
        "#Rows with missing values are removed\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Apply the clean_text function to preprocess the 'content' column\n",
        "df['content'] = df['content'].apply(clean_text)\n",
        "\n",
        "\n",
        "#The column contained unnecessary words like recorded reports or authors name, so remove these by removing everything from start to the first colon (:)\n",
        "df['content'] = df['content'].str.split(':', n=1).str[-1]\n",
        "\n",
        "#Remove the text 'copyright' with year present in some articles\n",
        "df['content'] = df['content'].str.replace('Copyright Business Recorder, \\d{4}\\.', '', regex=True)\n",
        "\n",
        "# Define a regular expression pattern to match lines with timestamps and program titles\n",
        "pattern = r'^\\d{2}:\\d{2}\\s[A-Z ]+'\n",
        "\n",
        "#Remove the rows with matching above pattern\n",
        "df = df[~df['content'].str.match(pattern)]\n",
        "\n",
        "#Path for output csv file\n",
        "output = '/content/drive/My Drive/clean_news_data.csv'\n",
        "\n",
        "# Open the output CSV file for writing. This piece of code is for eliminating rows with less than 10 words.\n",
        "with open(output, 'w', newline='', encoding='utf-8') as output_file:\n",
        "    writer = csv.writer(output_file)\n",
        "\n",
        "    # Iterate through rows in the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        # Write rows with 10 or more words in the 'content' column to the output file\n",
        "        if len(row['content'].split()) >= 10:\n",
        "            writer.writerow([row['content']])\n",
        "\n",
        "print(\"Preprocessed data saved to:\", output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCexwrMFfMo8"
      },
      "source": [
        "# Preprocessing of reviews_only file\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnZkA6R8ZbGB",
        "outputId": "c73be911-510b-42cc-feec-ca96a3761b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       1. Exterior and interior both are out class.2....\n",
            "1       eliability is a real strong point for the Coro...\n",
            "2       Grande is the best car  its fuel economy is be...\n",
            "3       Toyota Corolla 1982 GLexterior of this car is ...\n",
            "4       Exterior of car is awesome.Pick up and engine ...\n",
            "                              ...                        \n",
            "9495    Hello guys, my experience with Honda CG 125 ha...\n",
            "9496    this bike best but please launch ybr 125 Custo...\n",
            "9497    The look and feel of the the bike is good, the...\n",
            "9498    First of all look is good decent and stylish b...\n",
            "9499    Lorem Ipsum is simply dummy text of the printi...\n",
            "Name: Cleaned Review, Length: 4877, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Function to clean the text\n",
        "def clean_text(text):\n",
        "    #Remove everything except alphabets, integers, commas, and full stops.\n",
        "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s.,]', '', text)\n",
        "    # Removing extra full stops, question marks and commas and replacing them with single full stop, question mark and comma\n",
        "    cleaned_text = re.sub(r'\\.{2,}', '.', cleaned_text)\n",
        "    cleaned_text = re.sub(r'\\?{2,}', '?', cleaned_text)\n",
        "    cleaned_text = re.sub(r'\\,{2,}', ',' , cleaned_text)\n",
        "    return cleaned_text.strip()\n",
        "\n",
        "#Path of input csv file\n",
        "file_path = '/content/drive/MyDrive/reviews_only.csv'\n",
        "\n",
        "#Read csv file in df\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Remove empty rows\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove rows with less than 10 words\n",
        "df['Word Count'] = df['content'].apply(lambda x: len(x.split()))\n",
        "df = df[df['Word Count'] >= 10]\n",
        "\n",
        "# Clean the review text\n",
        "df['Cleaned Review'] = df['content'].apply(clean_text)\n",
        "\n",
        "# Drop the 'Word Count' column as it's no longer needed\n",
        "df.drop(columns=['Word Count'], inplace=True)\n",
        "\n",
        "# Remove duplicate rows based on the 'Cleaned Review' column\n",
        "df.drop_duplicates(subset=['Cleaned Review'], inplace=True)\n",
        "\n",
        "# extract the cleaned review text\n",
        "cleaned_reviews = df['Cleaned Review']\n",
        "print(cleaned_reviews)\n",
        "\n",
        "# Save the cleaned reviews to a separate CSV file\n",
        "cleaned_reviews.to_csv('/content/drive/MyDrive/cleaned_reviews.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBLzIm6ensbu"
      },
      "source": [
        "# Joining both files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-MR80uAmh_3",
        "outputId": "918d3ba5-d540-4733-fdb5-62bbff339d4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged file saved to: /content/drive/My Drive/complete_file.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load both files into DataFrames\n",
        "file1_path = '/content/drive/MyDrive/clean_news_data_.csv'\n",
        "file2_path = '/content/drive/MyDrive/cleaned_reviews.csv'\n",
        "news_df = pd.read_csv(file1_path)\n",
        "reviews_df = pd.read_csv(file2_path)\n",
        "\n",
        "# Concatenate both df\n",
        "merged_df = pd.concat([news_df, reviews_df], ignore_index=True)\n",
        "\n",
        "# Save the concatenated df to a new file\n",
        "output = '/content/drive/My Drive/complete_file.csv'\n",
        "merged_df.to_csv(output, index=False)\n",
        "\n",
        "print(\"Merged file saved to:\", output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atzuWS9ef2o-"
      },
      "source": [
        "# LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieBS3GTbnFlk",
        "outputId": "329634e7-e4bb-4cf0-f601-80f4b6c01b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "#installing necessary libraries\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3XyEc_SnOKT",
        "outputId": "56fb9460-a04a-4f94-9a70-963b86e3a7c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ3LotG4nYlg",
        "outputId": "62b16b06-5067-4150-bb0c-dce08aa6f2e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/171.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.40.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence_transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence_transformers-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-DjKTapnbkr",
        "outputId": "44947168-4357-49a8-f2c4-181f1ec9b753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ctransformers\n",
            "  Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from ctransformers) (0.23.4)\n",
            "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers) (9.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (3.15.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2024.6.2)\n",
            "Installing collected packages: ctransformers\n",
            "Successfully installed ctransformers-0.2.27\n"
          ]
        }
      ],
      "source": [
        "!pip install ctransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkxf6NQtnfJC",
        "outputId": "4c81fbf3-7e98-464f-da07-ac34046d87b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/232.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKyZNNionhVr",
        "outputId": "8749c9cc-2ddd-4412-c9d3-c21bdf5e4946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.10 (from langchain)\n",
            "  Downloading langchain_core-0.2.10-py3-none-any.whl (332 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.82-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.10->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.6 langchain-core-0.2.10 langchain-text-splitters-0.2.2 langsmith-0.1.82 orjson-3.10.5\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiipSzsunkWH"
      },
      "outputs": [],
      "source": [
        "#The Model used for this task is TheBloke/Mistral-7B-Instruct-v0.1-GGUF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "03fa3c3cbbd5453d94f1515d95fe87d0",
            "adbacb82ea164a998762520c83c2a058",
            "a1b53dac0a604515a6d8e5c2744c2699",
            "d0e052aed0d34866af960365e0833dba",
            "d95252fab66a44a3a884433f8e0145ed",
            "59ab83cf673d4f09b0d256be16a8da79",
            "1c96b46e97914895aceab0db0b99b4db",
            "1962f23079f14d29869701a694d144a0",
            "62ac2b5a1ef14990bd26b9e88e293b47",
            "ddbe8578a91c4092ac649ab7c73834ea",
            "c058df9880e84d628f02943ec6b336c9",
            "ee32b24ec1084ac3bfae2f9f9aad964e",
            "f0a2e1c0101b4f91ae3e8a735c462525",
            "d0acc29f9c284bfa87afffd5c630b359",
            "968807fc22dd4721a4800165ef7670d4",
            "6fa289456734488fa563525f9a58dec3",
            "691e059cb9ab4bd5b2c25ccf1b7fbd04",
            "037d3b42b812480e83b756170384c664",
            "4ddb2e587490422b8cd42084fed2e6d6",
            "d8ac22b41132435c8f50c02e0f6f0eb1",
            "f298e18af2c449d09522f415049ea1dd",
            "de9d60b1f3b64c848b16ce418888e689",
            "158533760fbb4f44be5fb1f1a13654d0",
            "46fc93602bc34714bf956d2962954e6e",
            "0aeabc7e134146108d2ccb2d3463a80d",
            "c0f2a3e9e1f14100958846e66a90d7df",
            "4ca4c78b618544a987d0a9d8743a0a1e",
            "d37427da26a3437880f349ce2f0e33a7",
            "3904c70b34f4427fa12c61ff00678744",
            "468c70a00d1b445dae40a955c168d4fc",
            "0792e82551af435881247545c044f933",
            "fc763d94507e4b68bb90e4cd0aa58b0e",
            "a027468a933e4edab30e6f5b3e40a8f2",
            "2228c197a5cf4991b09912862ffdccc2",
            "e7e9a0335f704a43a097f4699393ecb5",
            "069fde337d0f437f80c851df6b25c6c6",
            "4317b68b6d394a358699704da9dcdba1",
            "a5cca8a757f94c0dbc973f87f30b3064",
            "354ef23d3c63403bb8c057d4146dc161",
            "bc88db18d6f6445aa082088d75f9ec09",
            "36361be1628643abac9cc9109c5f33e6",
            "cb0056fa9bfe48f6895b45d36b6900aa",
            "1c6d9f361bd943d8bf2e60b57ed5aa4a",
            "d0b2d96292bf4b4e89b0095d7ad6a0c3"
          ]
        },
        "id": "wGwQYdqmVfrY",
        "outputId": "ad965300-925e-4785-f523-240a0d2ba018"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03fa3c3cbbd5453d94f1515d95fe87d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee32b24ec1084ac3bfae2f9f9aad964e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "158533760fbb4f44be5fb1f1a13654d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2228c197a5cf4991b09912862ffdccc2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "mistral-7b-instruct-v0.1.Q2_K.gguf:   0%|          | 0.00/3.08G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating questions based on text data.\n",
            "    Your goal is to prepare students for test and exams.\n",
            "    You do this by asking questions about the text below:\n",
            "\n",
            "    ------------\n",
            "    Cleaned Review1. Exterior and interior both are out class.2. Toyota Corolla Gli 1.3 vvti Manual ek bohot achi aur comfortable car hai.3. Suspension wise best hai.4. Performance wise bohot achi hai Alhamdullah  powerfull Engine Mashallah Motorway ho ya GT Road bohot dorr ti hai pick bho bohot zabardast hai value for money bhi best hai Thankyou Toyota for giving good vehicles.eliability is a real strong point for the Corolla, with the model itself finishing right near the top of the family car\n",
            "    ------------\n",
            "\n",
            "    Create questions that will help customers know about the automobile.\n",
            "    Make sure not to lose any important information.\n",
            "\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating practice questions based on text data.\n",
            "    Your goal is to prepare the student for exam and test.\n",
            "    We have received some practice questions to a certain extent: 1. What is the exterior and interior finish of the Toyota Corolla Gli?\n",
            "    2. What are the key features of the Toyota Corolla Gli?\n",
            "    3. How would you rate the suspension system in the Toyota Corolla Gli? \n",
            "    4. What is the performance of the Toyota Corolla Gli? \n",
            "    5. How does the Toyota Corolla handle driving on motorways or GT roads? \n",
            "    6. Would you say that the Toyota Corolla is reliable? \n",
            "    7. What are some of the features that make the Toyota Corolla a good value for money?.\n",
            "    We have the option to refine the existing questions or add new ones.\n",
            "    (only if necessary) with some more context below.\n",
            "    ------------\n",
            "    finishing right near the top of the family car category in our 2023 What Car Reliability Survey. Toyota as a brand performed admirably too, claiming second place beaten only by Lexus out of 32 car makers in our overall rankingsGrande is the best car  its fuel economy is best  grande is better than civic but value of money not better  I buy grande before one year this is most likely car and like a dream car it is very comfortable and style is beautiful  Toyota Grande is my dream and favorite\n",
            "    ------------\n",
            "\n",
            "    Given the new context, refine the original questions in English.\n",
            "    If the context is not helpful, please provide the original questions.\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:ctransformers:Number of tokens (513) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (514) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (515) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (516) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (517) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (518) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (519) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (520) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (521) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (522) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (523) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (524) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (525) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (526) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (527) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (528) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (529) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (530) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (531) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (532) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (533) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (534) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (535) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (536) exceeded maximum context length (512).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating practice questions based on text data.\n",
            "    Your goal is to prepare the student for exam and test.\n",
            "    We have received some practice questions to a certain extent: 1. What is the exterior and interior finish of the Toyota Corolla Grande?\n",
            "    2. What are the key features of the Toyota Corolla Grande?\n",
            "    3. How would you rate the suspension system in the Toyota Corolla Grande? \n",
            "    4. What is the performance of the Toyota Corolla Grande? \n",
            "    5. How does the Toyota Corolla Grande handle driving on motorways or GT roads? \n",
            "    6. Would you say that the Toyota Corolla Grande is reliable? \n",
            "    7. What are some of the features that make the Toyota Corolla Toyota Toyota Toyota Corolla Toyota Corolla Toyota Corolla.\n",
            "    We have the option to refine the existing questions or add new ones.\n",
            "    (only if necessary) with some more context below.\n",
            "    ------------\n",
            "    beautiful  Toyota Grande is my dream and favorite carGreaToyota Corolla 1982 GLexterior of this car is amazing and has a box type shape which resembles a Muscle Car.interior is also very good considering it is a 40 year old car.4k 1300cc engine is powerful and gives a fuel average of 1113 kmpl in city and 16 on long.i think this car is Value to money in this economy and you can find it under 10 lakh.Exterior of car is awesome.Pick up and engine performance is matchless. Most powerful than its\n",
            "    ------------\n",
            "\n",
            "    Given the new context, refine the original questions in English.\n",
            "    If the context is not helpful, please provide the original questions.\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:ctransformers:Number of tokens (513) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (514) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (515) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (516) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (517) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (518) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (519) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (520) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (521) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (522) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (523) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (524) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (525) exceeded maximum context length (512).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating practice questions based on text data.\n",
            "    Your goal is to prepare the student for exam and test.\n",
            "    We have received some practice questions to a certain extent: 1. What is the exterior finish of the Toyota Corolla Grande?\n",
            "    2. What are the key features of the Toyota Corolla Grande?\n",
            "    3. How would you rate the suspension system in the Toyota Corolla Grande? \n",
            "    4. What is the performance of the Toyota Corolla Grande? \n",
            "    5. How does the Toyota Corolla Grande handle driving on motorways or GT roads with highways?\n",
            "GT roads? GT roads?.\n",
            "    We have the option to refine the existing questions or add new ones.\n",
            "    (only if necessary) with some more context below.\n",
            "    ------------\n",
            "    performance is matchless. Most powerful than its competitors like honda. Ground clearance is good. Fuel average is very good. Suspension awesome. Price is on higher side which should be less. otherwise car is perfect with 55 remarks.Very nice looking top speed is about 240 kph but theres one issue it doesnt have rear ac vents but i think its ok because it has a very good front ac it cools the car in 2 minutes very smooth ride on mountains roads but a little uncomfortable on broken roads i have\n",
            "    ------------\n",
            "\n",
            "    Given the new context, refine the original questions in English.\n",
            "    If the context is not helpful, please provide the original questions.\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating practice questions based on text data.\n",
            "    Your goal is to prepare the student for exam and test.\n",
            "    We have received some practice questions to a certain extent: 1. What is the exterior finish of the Toyota Corolla Grande?\n",
            "    2. What are the key features of the Toyota Corolla Grande?\n",
            "    3. How would you rate the suspension system in the Toyota Corolla Grande? \n",
            "    4. What is the performance of the Toyota Corolla Grande? \n",
            "    5. How does the Toyota Corolla Grande handle driving on motorways or GT roads with highways?.\n",
            "    We have the option to refine the existing questions or add new ones.\n",
            "    (only if necessary) with some more context below.\n",
            "    ------------\n",
            "    but a little uncomfortable on broken roads i have another grande exactly same but made in 2017 when checked the suspension the 2023 one was higherTHE CAR IS GOOD BUT. NOT ENOUGH FEATURES AND ITS LIKE JUST LOOK AND PRICE IS VERY HIGH. ACCELERATION IS QUITE BETTER AND THE CAR IS GOOD AT ACCELERATIONS, AND SPEED ALSO HAS GOOD BRAKES. BUT BUILD QUALITY IS VERY BAD. ITS NOT ENOUGH TOUGH BUILT. AND PRICE IS ALSO HIGHER THAN THE OVERALL CAR IS. FUEL AVERAGE IT GIVES IS 12 TO 14 IN CITY AND MORE IN\n",
            "    ------------\n",
            "\n",
            "    Given the new context, refine the original questions in English.\n",
            "    If the context is not helpful, please provide the original questions.\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:ctransformers:Number of tokens (513) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (514) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (515) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (516) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (517) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (518) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (519) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (520) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (521) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (522) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (523) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (524) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (525) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (526) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (527) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (528) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (529) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (530) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (531) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (532) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (533) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (534) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (535) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (536) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (537) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (538) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (539) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (540) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (541) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (542) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (543) exceeded maximum context length (512).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating practice questions based on text data.\n",
            "    Your goal is to prepare the student for exam and test.\n",
            "    We have received some practice questions to a certain extent: 1. What is the exterior finish of the Toyota Corolla Grande?\n",
            "    2. What are the key features of the Toyota Corolla Grande?\n",
            "    3. How would you rate the suspension system in the Toyota Corolla Grande? \n",
            "    4. What is the performance of the Toyota Corolla Grande? \n",
            "    5. How does the Toyota Corolla Grande handle driving on motorways or GT roads with highways?.\n",
            "\n",
            "    REFINE QUESTIONS:\n",
            "    1. What would refinex. What are there were the car in 1. What is the exterior finish of the exterior finish of the suspension system.\n",
            "    We have the option to refine the existing questions or add new ones.\n",
            "    (only if necessary) with some more context below.\n",
            "    ------------\n",
            "    AVERAGE IT GIVES IS 12 TO 14 IN CITY AND MORE IN HIGHWAYS. QUITE GOOD BUT PRICE IS NOT SUITABLE.Toyota Name is Brand Level Altis give confidence to Driver All cars father Toyota altis x 1.6 and x 1.8 Altis grende Altis grende Altis grende Altis grende Altis grende Altis grende Altis grende Altis grende Altis grende Altis grende Altis grende Altis grende Altis grende Altis grende Altis grende Altis grendeThis is the best car I have ever seen. Its comfort,durability and reliability is\n",
            "    ------------\n",
            "\n",
            "    Given the new context, refine the original questions in English.\n",
            "    If the context is not helpful, please provide the original questions.\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating practice questions based on text data.\n",
            "    Your goal is to prepare the student for exam and test.\n",
            "    We have received some practice questions to a certain extent: 1. What are the exterior features of Toyota Altis?\n",
            "    2. What are the key features of Toyota Altis?\n",
            "    3. How would you rate the suspension system of the Toyota Altis?\n",
            "    4. Can you tell me about the performance of Toyota Altis?\n",
            "    5. How does the Toyota Altis handle driving on motorways or GT roads with highways?.\n",
            "    We have the option to refine the existing questions or add new ones.\n",
            "    (only if necessary) with some more context below.\n",
            "    ------------\n",
            "    seen. Its comfort,durability and reliability is unbelievable and it has good average.Its design is beautiful and its trunk capacity is very spacious.Its pickup is good and it has good pickup overall it is a very nice car.excellent car and good drive . road grip good. full stearing control. lights good. side mirror adjustable system very good. brakes and tyres excellent.very comfortable seats .good shape and good looking. market price affordable.power full engine and very good designValue for\n",
            "    ------------\n",
            "\n",
            "    Given the new context, refine the original questions in English.\n",
            "    If the context is not helpful, please provide the original questions.\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:ctransformers:Number of tokens (513) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (514) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (515) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (516) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (517) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (518) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (519) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (520) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (521) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (522) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (523) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (524) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (525) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (526) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (527) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (528) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (529) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (530) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (531) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (532) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (533) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (534) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (535) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (536) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (537) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (538) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (539) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (540) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (541) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (542) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (543) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (544) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (545) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (546) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (547) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (548) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (549) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (550) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (551) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (552) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (553) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (554) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (555) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (556) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (557) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (558) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (559) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (560) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (561) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (562) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (563) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (564) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (565) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (566) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (567) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (568) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (569) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (570) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (571) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (572) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (573) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (574) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (575) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (576) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (577) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (578) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (579) exceeded maximum context length (512).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating practice questions based on text data.\n",
            "    Your goal is to prepare the student for exam and test.\n",
            "    We have received some practice questions to a certain extent: 1. What are the exterior features of Toyota Altis?\n",
            "    2. What are the key features of Toyota Altis?\n",
            "    3. How would you rate the suspension system of the Toyota Altis?\n",
            "    4. Can you tell me about the performance of Toyota Altis?\n",
            "    5. How does the Toyota Altis handle driving on motorways or GT roads with highways?\n",
            "    REFINED QUESTIONS:\n",
            "    1. What are some notable exterior features of the Toyota Altis, such as its design and trunk capacity?\n",
            "    2. Can you describe the key features of the Toyota Altis, including its comfort, durability, reliability, and market price?\n",
            "    3. How would you rate the suspension system of the Toyota Altis, based on the customer feedback provided in the context?\n",
            "    4. According to the context, what are there is available, how does the key features, what is given, what are there seems like, can you have a good road grip, what are some notable features, what is given, what are any information, what is available, what is given, what is provided, what are there is the car reviews, what are.\n",
            "    We have the option to refine the existing questions or add new ones.\n",
            "    (only if necessary) with some more context below.\n",
            "    ------------\n",
            "    full engine and very good designValue for Money Great Fuel Average Comfortable Seats Limited Leg room  Big Trunk  1.2 isnt as under powered as people say Build Quality needs attention Interior and Exterior of tye car is far better than Yaris Tires need to be changed for betterexellent road grip n good in mild off roading n never touch the high speed breakers.suspension is far better than previous one.  spacious, smooth cvt pic n cruise control. feul aver 13.5 in city n 15 on longs. good\n",
            "    ------------\n",
            "\n",
            "    Given the new context, refine the original questions in English.\n",
            "    If the context is not helpful, please provide the original questions.\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:ctransformers:Number of tokens (513) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (514) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (515) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (516) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (517) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (518) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (519) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (520) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (521) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (522) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (523) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (524) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (525) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (526) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (527) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (528) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (529) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (530) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (531) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (532) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (533) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (534) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (535) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (536) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (537) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (538) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (539) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (540) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (541) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (542) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (543) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (544) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (545) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (546) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (547) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (548) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (549) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (550) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (551) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (552) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (553) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (554) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (555) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (556) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (557) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (558) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (559) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (560) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (561) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (562) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (563) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (564) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (565) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (566) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (567) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (568) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (569) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (570) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (571) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (572) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (573) exceeded maximum context length (512).\n",
            "WARNING:ctransformers:Number of tokens (574) exceeded maximum context length (512).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating practice questions based on text data.\n",
            "    Your goal is to prepare the student for exam and test.\n",
            "    We have received some practice questions to a certain extent: 1. What are some notable exterior features of the notable exterior features that are notable exterior features that the notable exterior design and the key exterior features of the notable external characteristics of the most prominent exterior features of the notable exterior features of the notable exterior features of the noticeable exterior features of the notable exterior features of the notable exterior features that you.\n",
            "    We have the option to refine the existing questions or add new ones.\n",
            "    (only if necessary) with some more context below.\n",
            "    ------------\n",
            "    feul aver 13.5 in city n 15 on longs. good handling.fully satisfied to have it.Totally Comfortable and having excellent fuel average and a reliable travel partner . A durable and powerful engine with good quality interior and sleek exterior design, aggressive look makes it the best available sedan in Pakistani market however some improvements can be done in upcoming model such as lane assist, heated seats, most important hybrid version,Good looking exterior, comfortable seats, only sometimes\n",
            "    ------------\n",
            "\n",
            "    Given the new context, refine the original questions in English.\n",
            "    If the context is not helpful, please provide the original questions.\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating practice questions based on text data.\n",
            "    Your goal is to prepare the student for exam and test.\n",
            "    We have received some practice questions to a certain extent: 1. What are some notable exterior features of the car?\n",
            "    2. How good is the handling of the car?\n",
            "    3. How satisfied are you with the car's fuel average and overall performance?\n",
            "    4. Are there any improvements that could be made to the car for the upcoming model?\n",
            "    5. What kind of hybrid version would you like in the car?.\n",
            "    We have the option to refine the existing questions or add new ones.\n",
            "    (only if necessary) with some more context below.\n",
            "    ------------\n",
            "    exterior, comfortable seats, only sometimes noisy from dashboard otherwise fine. Fuel average 14 to 15 with AC and 16 to 18 without AC on long route depending on speed and driving habits. Overpriced as other cars. Built quality is just ok.Best fuel economy, comfort ride, sufficient space, excellent boot space, good value for money. In city 1114 , on long 15 19kml. Good braking . good handling and road grip. Stylish car. Smooth drive. Parts availability. Fully satisfied with this car Honda City\n",
            "    ------------\n",
            "\n",
            "    Given the new context, refine the original questions in English.\n",
            "    If the context is not helpful, please provide the original questions.\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert at creating practice questions based on text data.\n",
            "    Your goal is to prepare the student for exam and test.\n",
            "    We have received some practice questions to a certain extent: 1. What are some notable exterior features of the car?\n",
            "    2. How good is the handling of the car?\n",
            "    3. How satisfied are you with the car's fuel average and overall performance?\n",
            "    4. Are there any improvements that could be made to the car for the upcoming model?\n",
            "    5. What kind of hybrid version would you like in the car?.\n",
            "    We have the option to refine the existing questions or add new ones.\n",
            "    (only if necessary) with some more context below.\n",
            "    ------------\n",
            "    Fully satisfied with this car Honda City 1.5 ivtec prosmateccar is stylish and good looking as compared to yaris and alsvin, the down grade in exterior are thin tyres thats why I changed them with continental tyres size 18565R15 due to which grip and smoothness of car really enhancedthe biggest downgrade of this model is that its paint quality is very patheticinterior wise car is good and really spacious as compared to other sedans in market and have good features everything works perfectly.\n",
            "    ------------\n",
            "\n",
            "    Given the new context, refine the original questions in English.\n",
            "    If the context is not helpful, please provide the original questions.\n",
            "    QUESTIONS:\n",
            "    \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from langchain.llms import CTransformers\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains import RetrievalQA\n",
        "import os\n",
        "\n",
        "# Loading Language model\n",
        "def load_llm():\n",
        "    # Load the locally downloaded model here\n",
        "    llm = CTransformers(\n",
        "        model=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
        "        model_type=\"mistral\",\n",
        "        max_new_tokens=1048,\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return llm\n",
        "\n",
        "# File Processing\n",
        "def file_processing(file_path):\n",
        "    # Load data from CSV\n",
        "    with open(file_path, 'r') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        data = \"\"\n",
        "        for row in reader:\n",
        "            data += row[0]\n",
        "\n",
        "    question_gen = data\n",
        "\n",
        "    splitter_ques_gen = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=50\n",
        "    )\n",
        "\n",
        "    chunks_ques_gen = splitter_ques_gen.split_text(question_gen)\n",
        "\n",
        "    document_ques_gen = [Document(page_content=t) for t in chunks_ques_gen]\n",
        "\n",
        "    return document_ques_gen\n",
        "\n",
        "# Prompt Engineering\n",
        "def llm_pipeline(file_path):\n",
        "    document_ques_gen = file_processing(file_path)\n",
        "    llm_ques_gen_pipeline = load_llm()\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "    You are an expert at creating questions based on text data.\n",
        "    Your goal is to prepare students for test and exams.\n",
        "    You do this by asking questions about the text below:\n",
        "\n",
        "    ------------\n",
        "    {text}\n",
        "    ------------\n",
        "\n",
        "    Create questions that will help customers know about the automobile.\n",
        "    Make sure not to lose any important information.\n",
        "\n",
        "    QUESTIONS:\n",
        "    \"\"\"\n",
        "\n",
        "    PROMPT_QUESTIONS = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
        "\n",
        "    refine_template = (\"\"\"\n",
        "    You are an expert at creating practice questions based on text data.\n",
        "    Your goal is to prepare the student for exam and test.\n",
        "    We have received some practice questions to a certain extent: {existing_answer}.\n",
        "    We have the option to refine the existing questions or add new ones.\n",
        "    (only if necessary) with some more context below.\n",
        "    ------------\n",
        "    {text}\n",
        "    ------------\n",
        "\n",
        "    Given the new context, refine the original questions in English.\n",
        "    If the context is not helpful, please provide the original questions.\n",
        "    QUESTIONS:\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "    REFINE_PROMPT_QUESTIONS = PromptTemplate(\n",
        "        input_variables=[\"existing_answer\", \"text\"],\n",
        "        template=refine_template,\n",
        "    )\n",
        "\n",
        "    ques_gen_chain = load_summarize_chain(llm=llm_ques_gen_pipeline,\n",
        "                                          chain_type=\"refine\",\n",
        "                                          verbose=True,\n",
        "                                          question_prompt=PROMPT_QUESTIONS,\n",
        "                                          refine_prompt=REFINE_PROMPT_QUESTIONS)\n",
        "\n",
        "    ques = ques_gen_chain.run(document_ques_gen)\n",
        "\n",
        "    llm_answer_gen = load_llm()\n",
        "\n",
        "    ques_list = ques.split(\"\\n\")\n",
        "    filtered_ques_list = [element for element in ques_list if element.endswith('?') or element.endswith('.')]\n",
        "\n",
        "    answer_generation_chain = RetrievalQA.from_chain_type(llm=llm_answer_gen,\n",
        "                                                          chain_type=\"stuff\")\n",
        "\n",
        "    return answer_generation_chain, filtered_ques_list\n",
        "\n",
        "# Generating CSV file in the drive\n",
        "def get_csv(file_path):\n",
        "    answer_generation_chain, ques_list = llm_pipeline(file_path)\n",
        "    base_folder = 'output/'\n",
        "    if not os.path.isdir(base_folder):\n",
        "        os.mkdir(base_folder)\n",
        "    output_file = os.path.join(base_folder, \"QA.csv\")\n",
        "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerow([\"Question\", \"Answer\"])\n",
        "\n",
        "        for question in ques_list:\n",
        "            print(\"Question: \", question)\n",
        "            answer = answer_generation_chain.run(question)\n",
        "            print(\"Answer: \", answer)\n",
        "            print(\"--------------------------------------------------\\n\\n\")\n",
        "\n",
        "            # Save answer to CSV file\n",
        "            csv_writer.writerow([question, answer])\n",
        "    return output_file\n",
        "\n",
        "csv_file_path = \"/content/drive/MyDrive/complete_file.csv\"\n",
        "output_file = get_csv(csv_file_path)\n",
        "print(\"CSV file generated:\", output_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO0jxDMKW593",
        "outputId": "aac3149d-d300-448c-85a5-ce997a1d70cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.6)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.10)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.82)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain_community) (2.7.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain_community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain_community) (2.18.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.6 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain_community"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "037d3b42b812480e83b756170384c664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03fa3c3cbbd5453d94f1515d95fe87d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adbacb82ea164a998762520c83c2a058",
              "IPY_MODEL_a1b53dac0a604515a6d8e5c2744c2699",
              "IPY_MODEL_d0e052aed0d34866af960365e0833dba"
            ],
            "layout": "IPY_MODEL_d95252fab66a44a3a884433f8e0145ed"
          }
        },
        "069fde337d0f437f80c851df6b25c6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36361be1628643abac9cc9109c5f33e6",
            "max": 3083097760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb0056fa9bfe48f6895b45d36b6900aa",
            "value": 3083097760
          }
        },
        "0792e82551af435881247545c044f933": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0aeabc7e134146108d2ccb2d3463a80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_468c70a00d1b445dae40a955c168d4fc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0792e82551af435881247545c044f933",
            "value": 1
          }
        },
        "158533760fbb4f44be5fb1f1a13654d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46fc93602bc34714bf956d2962954e6e",
              "IPY_MODEL_0aeabc7e134146108d2ccb2d3463a80d",
              "IPY_MODEL_c0f2a3e9e1f14100958846e66a90d7df"
            ],
            "layout": "IPY_MODEL_4ca4c78b618544a987d0a9d8743a0a1e"
          }
        },
        "1962f23079f14d29869701a694d144a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6d9f361bd943d8bf2e60b57ed5aa4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c96b46e97914895aceab0db0b99b4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2228c197a5cf4991b09912862ffdccc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7e9a0335f704a43a097f4699393ecb5",
              "IPY_MODEL_069fde337d0f437f80c851df6b25c6c6",
              "IPY_MODEL_4317b68b6d394a358699704da9dcdba1"
            ],
            "layout": "IPY_MODEL_a5cca8a757f94c0dbc973f87f30b3064"
          }
        },
        "354ef23d3c63403bb8c057d4146dc161": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36361be1628643abac9cc9109c5f33e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3904c70b34f4427fa12c61ff00678744": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4317b68b6d394a358699704da9dcdba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c6d9f361bd943d8bf2e60b57ed5aa4a",
            "placeholder": "​",
            "style": "IPY_MODEL_d0b2d96292bf4b4e89b0095d7ad6a0c3",
            "value": " 3.08G/3.08G [00:34&lt;00:00, 197MB/s]"
          }
        },
        "468c70a00d1b445dae40a955c168d4fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46fc93602bc34714bf956d2962954e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d37427da26a3437880f349ce2f0e33a7",
            "placeholder": "​",
            "style": "IPY_MODEL_3904c70b34f4427fa12c61ff00678744",
            "value": "Fetching 1 files: 100%"
          }
        },
        "4ca4c78b618544a987d0a9d8743a0a1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ddb2e587490422b8cd42084fed2e6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ab83cf673d4f09b0d256be16a8da79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62ac2b5a1ef14990bd26b9e88e293b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "691e059cb9ab4bd5b2c25ccf1b7fbd04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa289456734488fa563525f9a58dec3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "968807fc22dd4721a4800165ef7670d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f298e18af2c449d09522f415049ea1dd",
            "placeholder": "​",
            "style": "IPY_MODEL_de9d60b1f3b64c848b16ce418888e689",
            "value": " 31.0/31.0 [00:00&lt;00:00, 522B/s]"
          }
        },
        "a027468a933e4edab30e6f5b3e40a8f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1b53dac0a604515a6d8e5c2744c2699": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1962f23079f14d29869701a694d144a0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62ac2b5a1ef14990bd26b9e88e293b47",
            "value": 1
          }
        },
        "a5cca8a757f94c0dbc973f87f30b3064": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbacb82ea164a998762520c83c2a058": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59ab83cf673d4f09b0d256be16a8da79",
            "placeholder": "​",
            "style": "IPY_MODEL_1c96b46e97914895aceab0db0b99b4db",
            "value": "Fetching 1 files: 100%"
          }
        },
        "bc88db18d6f6445aa082088d75f9ec09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c058df9880e84d628f02943ec6b336c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0f2a3e9e1f14100958846e66a90d7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc763d94507e4b68bb90e4cd0aa58b0e",
            "placeholder": "​",
            "style": "IPY_MODEL_a027468a933e4edab30e6f5b3e40a8f2",
            "value": " 1/1 [00:34&lt;00:00, 35.00s/it]"
          }
        },
        "cb0056fa9bfe48f6895b45d36b6900aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0acc29f9c284bfa87afffd5c630b359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ddb2e587490422b8cd42084fed2e6d6",
            "max": 31,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8ac22b41132435c8f50c02e0f6f0eb1",
            "value": 31
          }
        },
        "d0b2d96292bf4b4e89b0095d7ad6a0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0e052aed0d34866af960365e0833dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddbe8578a91c4092ac649ab7c73834ea",
            "placeholder": "​",
            "style": "IPY_MODEL_c058df9880e84d628f02943ec6b336c9",
            "value": " 1/1 [00:00&lt;00:00,  1.85it/s]"
          }
        },
        "d37427da26a3437880f349ce2f0e33a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8ac22b41132435c8f50c02e0f6f0eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d95252fab66a44a3a884433f8e0145ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddbe8578a91c4092ac649ab7c73834ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de9d60b1f3b64c848b16ce418888e689": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7e9a0335f704a43a097f4699393ecb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_354ef23d3c63403bb8c057d4146dc161",
            "placeholder": "​",
            "style": "IPY_MODEL_bc88db18d6f6445aa082088d75f9ec09",
            "value": "mistral-7b-instruct-v0.1.Q2_K.gguf: 100%"
          }
        },
        "ee32b24ec1084ac3bfae2f9f9aad964e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0a2e1c0101b4f91ae3e8a735c462525",
              "IPY_MODEL_d0acc29f9c284bfa87afffd5c630b359",
              "IPY_MODEL_968807fc22dd4721a4800165ef7670d4"
            ],
            "layout": "IPY_MODEL_6fa289456734488fa563525f9a58dec3"
          }
        },
        "f0a2e1c0101b4f91ae3e8a735c462525": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_691e059cb9ab4bd5b2c25ccf1b7fbd04",
            "placeholder": "​",
            "style": "IPY_MODEL_037d3b42b812480e83b756170384c664",
            "value": "config.json: 100%"
          }
        },
        "f298e18af2c449d09522f415049ea1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc763d94507e4b68bb90e4cd0aa58b0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}